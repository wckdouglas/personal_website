{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jZV_yu-nn4e"
      },
      "source": [
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/src')\n",
        "from utils import Bootstrap\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import jax.numpy as jnp\n",
        "from jax import jit, grad, lax, random, value_and_grad, vmap\n",
        "from jax.experimental import stax, optimizers\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import logging \n",
        "logging.basicConfig(level = logging.INFO)\n",
        "logger = logging.getLogger('Autoencoder')\n",
        "plt.rc('axes', labelsize=15)\n",
        "plt.rc('xtick', labelsize=15)\n",
        "plt.rc('ytick', labelsize=15)\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "ndim = 2\n",
        "lr = 0.01\n",
        "batch_size = 60\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQESEpcESh-r"
      },
      "source": [
        "def plot_dim_reduction(ax, predicted, target, title='', pca=False):\n",
        "    dim_reduced = pd.DataFrame(predicted, columns=['Dim 1','Dim 2']) \\\n",
        "        .assign(target = target)  \\\n",
        "        .assign(target = lambda d: d.target.map(dict(zip(set(y),target_names))))\n",
        "\n",
        "    sns.scatterplot(data=dim_reduced, x= 'Dim 1', y ='Dim 2',hue ='target', ax=ax)\n",
        "    ax.set_title(title, size=15)\n",
        "    if pca:\n",
        "        ax.set_xlabel('PC1')\n",
        "        ax.set_ylabel('PC2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qpOVEOUn1fQ"
      },
      "source": [
        "encoder_init, encode = stax.serial(\n",
        "    stax.Dense(5), stax.Relu,\n",
        "    stax.Dense(ndim), stax.Sigmoid\n",
        ")\n",
        "\n",
        "decoder_init, decode = stax.serial(\n",
        "    stax.Dense(X.shape[1]), stax.Sigmoid,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_npgX1Bo7fI"
      },
      "source": [
        "rng = random.PRNGKey(1)  # fixed prng key for evaluation\n",
        "encode_rng, decode_rng = random.split(rng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu-8zK_ipFHy"
      },
      "source": [
        "@jit\n",
        "def loss(predicted, Y):\n",
        "    #mse function\n",
        "    return jnp.mean( (Y - predicted)**2 )\n",
        "\n",
        "@jit\n",
        "def VAE(params, x):\n",
        "    encoded = jit(encode)(params['encoder'], x)\n",
        "    decoding = jit(decode)(params['decoder'], encoded)\n",
        "    return loss(decoding, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kalRLHQpJud"
      },
      "source": [
        "epoch = 1000\n",
        "losses = np.zeros(epoch)\n",
        "params = {}\n",
        "_, params['encoder'] = encoder_init(encode_rng, (batch_size, X.shape[1]))\n",
        "_, params['decoder'] = decoder_init(decode_rng, (batch_size, ndim))\n",
        "opt_init, opt_update, get_params = optimizers.adam(step_size = lr)\n",
        "opt_state = opt_init(params)\n",
        "bootstrap = Bootstrap()\n",
        "minibatches = bootstrap.bootstrap(X, group_size = batch_size, n_boots = epoch)\n",
        "\n",
        "for i in range(epoch):\n",
        "    minibatch = X[next(minibatches)]\n",
        "    rmse, gradients = value_and_grad(VAE)(get_params(opt_state), minibatch)\n",
        "    losses[i] = rmse.mean()\n",
        "    opt_state = opt_update(i, gradients, opt_state)\n",
        "    if (i+1) % (epoch//5) == 0:\n",
        "        logger.info('%i iteration: RMSE = %.2f' %(i+1, rmse))\n",
        "plt.plot(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_f_2hzNOQBi"
      },
      "source": [
        "fig = plt.figure(figsize=(8,4))\n",
        "ax = fig.add_subplot(121)\n",
        "vae = encode(params['encoder'], X)\n",
        "plot_dim_reduction(ax, vae, y, title='Autoencoder', pca=False)\n",
        "ax.legend().set_visible(False)\n",
        "pca = PCA(n_components=2).fit_transform(X)\n",
        "ax = fig.add_subplot(122)\n",
        "plot_dim_reduction(ax, pca, y, title = 'PCA', pca=True)\n",
        "fig.tight_layout()\n",
        "ax.legend(fontsize=15, title='', bbox_to_anchor=(1,1), frameon=False)\n",
        "sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIRPeZdD9VsD"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "vae_model = SVC()\n",
        "vae_model.fit(vae, y)\n",
        "\n",
        "pca_model = SVC()\n",
        "pca_model.fit(pca, y)\n",
        "print('Logit for VAE: %.3f vs Logit for PCA: %.3f' %(vae_model.score(vae,y), pca_model.score(pca,y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_NXEvk0i3_b"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}